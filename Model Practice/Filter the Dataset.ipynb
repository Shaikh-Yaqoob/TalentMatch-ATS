{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fd94675-35b4-4253-ba4b-7aecd898d049",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72f40f9f-53f2-435b-8064-cf66931e12b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved file:\n",
      "Columns: Index(['Resume', 'Category'], dtype='object')\n",
      "Total rows: 23640\n",
      "Data types:\n",
      " Resume      object\n",
      "Category    object\n",
      "dtype: object\n",
      "Sample data:\n",
      "                                               Resume                Category\n",
      "0  Database Administrator- Family Private Care LL...  Database Administrator\n",
      "1  Database Administrator Database Administrator ...  Database Administrator\n",
      "2  Oracle Database Administrator Oracle Database ...  Database Administrator\n",
      "3  Amazon Redshift Administrator and ETL Develope...  Database Administrator\n",
      "4  Scrum Master Scrum Master Scrum Master Richmon...  Database Administrator\n",
      "5  Oracle Database Administrator Oracle Database ...  Database Administrator\n",
      "6  Oracle Database Administrator Oracle Database ...  Database Administrator\n",
      "7  Lead Database Administrator/Developer Lead Dat...  Database Administrator\n",
      "8  Database Administrator / Database Developer Da...  Database Administrator\n",
      "9  Oracle Database Administrator Oracle Database ...  Database Administrator\n"
     ]
    }
   ],
   "source": [
    "# Load and verify the saved file\n",
    "data = pd.read_csv('resumes_combined_updated_utf8.csv')\n",
    "print(\"\\nSaved file:\")\n",
    "print(\"Columns:\", data.columns)\n",
    "print(\"Total rows:\", len(data))\n",
    "print(\"Data types:\\n\", data.dtypes)\n",
    "print(\"Sample data:\\n\", data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b505bff2-bc57-43a2-9245-e3a2a9332309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Categories and Their Counts:\n",
      "Category\n",
      "Software Developer                                                                                                                                                                                                                                                                                                                                                                                                                                                             5882\n",
      "Systems Administrator                                                                                                                                                                                                                                                                                                                                                                                                                                                          4178\n",
      "Web Developer                                                                                                                                                                                                                                                                                                                                                                                                                                                                  3565\n",
      "Database Administrator                                                                                                                                                                                                                                                                                                                                                                                                                                                         2812\n",
      "Java Developer                                                                                                                                                                                                                                                                                                                                                                                                                                                                 2488\n",
      "Network Administrator                                                                                                                                                                                                                                                                                                                                                                                                                                                          2284\n",
      "Data Scientist                                                                                                                                                                                                                                                                                                                                                                                                                                                                 2094\n",
      "Sales Manager                                                                                                                                                                                                                                                                                                                                                                                                                                                                   156\n",
      "HR Manager                                                                                                                                                                                                                                                                                                                                                                                                                                                                      154\n",
      " JUnit                                                                                                                                                                                                                                                                                                                                                                                                                                                                            2\n",
      " Query Analyzer                                                                                                                                                                                                                                                                                                                                                                                                                                                                   1\n",
      " VA May 2006 to April 2009 District of Columbia                                                                                                                                                                                                                                                                                                                                                                                                                                   1\n",
      " patching                                                                                                                                                                                                                                                                                                                                                                                                                                                                         1\n",
      " project time schedule                                                                                                                                                                                                                                                                                                                                                                                                                                                            1\n",
      " guiding                                                                                                                                                                                                                                                                                                                                                                                                                                                                          1\n",
      " Entity Framework                                                                                                                                                                                                                                                                                                                                                                                                                                                                 1\n",
      " SVN-basic                                                                                                                                                                                                                                                                                                                                                                                                                                                                        1\n",
      " C++                                                                                                                                                                                                                                                                                                                                                                                                                                                                              1\n",
      " Glue                                                                                                                                                                                                                                                                                                                                                                                                                                                                             1\n",
      " NodeJS.Â  â¢ Utilized MEAN stack                                                                                                                                                                                                                                                                                                                                                                                                                                                1\n",
      " Unions in Oracle data base to fetch the data.Â  â¢ Developed Applications using Rule Engines-Jboss Drools4.x                                                                                                                                                                                                                                                                                                                                                                    1\n",
      " Excel                                                                                                                                                                                                                                                                                                                                                                                                                                                                            1\n",
      " clarifications on specifications and resolve issues on Ambiguity.Â  â¢ Preparing the Proof of Concepts.Â  â¢ Brain Storming the Requirements and Preparing the Design documentÂ  â¢ Preparing the UML diagrams (Use Case                                                                                                                                                                                                                                                      1\n",
      " deploy and manage all internal web- based training                                                                                                                                                                                                                                                                                                                                                                                                                               1\n",
      " Angularjs                                                                                                                                                                                                                                                                                                                                                                                                                                                                        1\n",
      " CSS and JavaScript.Â  â¢ Developed UI using HTML                                                                                                                                                                                                                                                                                                                                                                                                                                1\n",
      " Integration                                                                                                                                                                                                                                                                                                                                                                                                                                                                      1\n",
      " was responsible to port                                                                                                                                                                                                                                                                                                                                                                                                                                                          1\n",
      " Triggers.â  Ä Extensively used JDBC to access the database objects.â  Ä Prepared UNIT test cases                                                                                                                                                                                                                                                                                                                                                                             1\n",
      " J2EE                                                                                                                                                                                                                                                                                                                                                                                                                                                                             1\n",
      " MySQL5.1/4.1                                                                                                                                                                                                                                                                                                                                                                                                                                                                     1\n",
      " account problems                                                                                                                                                                                                                                                                                                                                                                                                                                                                 1\n",
      " and administer 17+ web and database servers to include Network Load Balancing                                                                                                                                                                                                                                                                                                                                                                                                    1\n",
      " branching and writing config specs for ClearCase.Ã¡ Ä½ Migrate EAR/JAR files to non-prod WebLogic/WebSphere/ILOG RES servers.Ã¡ Ä½ Coordinating the AML production releases with WebLogic/WebSphere webadmin and DB2/Oracle DBA.Ã¡ Ä½ Providing production support for AML FE                                                                                                                                                                                                    1\n",
      " credit conditions and so on based on the options dialed through the phone. The struts 2.0 framework was established to decouple the controller pattern from the whole front end development and set the view layer. We configured the pom.xml for the Maven-based build to include the libraries and configured the web.xml to apply the filter and filter mappings for the struts packages. Then we configured using struts.xml all the actions for struts 2.0 to be used       1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Total unique categories: 35\n",
      "Total rows in dataset: 23640\n"
     ]
    }
   ],
   "source": [
    "# Get unique categories and their counts\n",
    "category_counts = data['Category'].value_counts()\n",
    "\n",
    "# Print the results\n",
    "print(\"Unique Categories and Their Counts:\")\n",
    "print(category_counts)\n",
    "print(f\"\\nTotal unique categories: {len(category_counts)}\")\n",
    "print(f\"Total rows in dataset: {len(data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9fad6fa-cbb8-4fdc-80b8-39b15bfafa25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('resumes_combined_updated_utf8.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3ed18bd-12de-4f71-b7c2-f00e854621dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the categories to keep\n",
    "keep_categories = [\n",
    "    'Software Developer',\n",
    "    'Systems Administrator',\n",
    "    'Web Developer',\n",
    "    'Database Administrator',\n",
    "    'Java Developer',\n",
    "    'Network Administrator',\n",
    "    'Data Scientist'\n",
    "]\n",
    "\n",
    "# Filter the dataset\n",
    "df_filtered = df[df['Category'].isin(keep_categories)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56cebde8-9d90-4e4a-ac4e-bd5739dcca07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows after filtering: 23303\n",
      "\n",
      "Unique Categories and Their Counts:\n",
      "Category\n",
      "Software Developer        5882\n",
      "Systems Administrator     4178\n",
      "Web Developer             3565\n",
      "Database Administrator    2812\n",
      "Java Developer            2488\n",
      "Network Administrator     2284\n",
      "Data Scientist            2094\n",
      "Name: count, dtype: int64\n",
      "Total unique categories: 7\n",
      "\n",
      "Data types:\n",
      " Resume      object\n",
      "Category    object\n",
      "dtype: object\n",
      "\n",
      "Sample data:\n",
      "                                               Resume                Category\n",
      "0  Database Administrator- Family Private Care LL...  Database Administrator\n",
      "1  Database Administrator Database Administrator ...  Database Administrator\n",
      "2  Oracle Database Administrator Oracle Database ...  Database Administrator\n",
      "3  Amazon Redshift Administrator and ETL Develope...  Database Administrator\n",
      "4  Scrum Master Scrum Master Scrum Master Richmon...  Database Administrator\n",
      "5  Oracle Database Administrator Oracle Database ...  Database Administrator\n",
      "6  Oracle Database Administrator Oracle Database ...  Database Administrator\n",
      "7  Lead Database Administrator/Developer Lead Dat...  Database Administrator\n",
      "8  Database Administrator / Database Developer Da...  Database Administrator\n",
      "9  Oracle Database Administrator Oracle Database ...  Database Administrator\n"
     ]
    }
   ],
   "source": [
    "# Verify row count\n",
    "print(f\"Total rows after filtering: {len(df_filtered)}\")\n",
    "\n",
    "# Verify unique categories and their counts\n",
    "category_counts = df_filtered['Category'].value_counts()\n",
    "print(\"\\nUnique Categories and Their Counts:\")\n",
    "print(category_counts)\n",
    "print(f\"Total unique categories: {len(category_counts)}\")\n",
    "\n",
    "# Check data types\n",
    "print(\"\\nData types:\\n\", df_filtered.dtypes)\n",
    "\n",
    "# View sample data\n",
    "print(\"\\nSample data:\\n\", df_filtered.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab8f4c21-be84-40b9-a542-2a416b3b8cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asad Computers\\AppData\\Local\\Temp\\ipykernel_14968\\3023477380.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['Resume'] = df_filtered['Resume'].astype(str).replace('nan', 'Unknown')\n",
      "C:\\Users\\Asad Computers\\AppData\\Local\\Temp\\ipykernel_14968\\3023477380.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['Category'] = df_filtered['Category'].astype('category')\n"
     ]
    }
   ],
   "source": [
    "# Ensure consistent data types\n",
    "df_filtered['Resume'] = df_filtered['Resume'].astype(str).replace('nan', 'Unknown')\n",
    "df_filtered['Category'] = df_filtered['Category'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7fdea8d-c7bb-4503-976c-bcd950857853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataset and create a copy\n",
    "df_filtered = df[df['Category'].isin(keep_categories)].copy()\n",
    "\n",
    "# Now safely modify df_filtered\n",
    "df_filtered['Resume'] = df_filtered['Resume'].astype(str).replace('nan', 'Unknown')\n",
    "df_filtered['Category'] = df_filtered['Category'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1acdc883-be02-4251-a998-1a6d59779866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the filtered dataset\n",
    "df_filtered.to_csv('resumes_filtered_utf8.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "91799474-424a-4bd8-adc9-2eb012ea05c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved file:\n",
      "Columns: Index(['Resume', 'Category'], dtype='object')\n",
      "Total rows: 23303\n",
      "Data types:\n",
      " Resume      object\n",
      "Category    object\n",
      "dtype: object\n",
      "Sample data:\n",
      "                                               Resume                Category\n",
      "0  Database Administrator- Family Private Care LL...  Database Administrator\n",
      "1  Database Administrator Database Administrator ...  Database Administrator\n",
      "2  Oracle Database Administrator Oracle Database ...  Database Administrator\n",
      "3  Amazon Redshift Administrator and ETL Develope...  Database Administrator\n",
      "4  Scrum Master Scrum Master Scrum Master Richmon...  Database Administrator\n",
      "5  Oracle Database Administrator Oracle Database ...  Database Administrator\n",
      "6  Oracle Database Administrator Oracle Database ...  Database Administrator\n",
      "7  Lead Database Administrator/Developer Lead Dat...  Database Administrator\n",
      "8  Database Administrator / Database Developer Da...  Database Administrator\n",
      "9  Oracle Database Administrator Oracle Database ...  Database Administrator\n",
      "\n",
      "Unique Categories in saved file:\n",
      "Category\n",
      "Software Developer        5882\n",
      "Systems Administrator     4178\n",
      "Web Developer             3565\n",
      "Database Administrator    2812\n",
      "Java Developer            2488\n",
      "Network Administrator     2284\n",
      "Data Scientist            2094\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load and verify the saved file\n",
    "df_verified = pd.read_csv('resumes_filtered_utf8.csv')\n",
    "print(\"\\nSaved file:\")\n",
    "print(\"Columns:\", df_verified.columns)\n",
    "print(\"Total rows:\", len(df_verified))\n",
    "print(\"Data types:\\n\", df_verified.dtypes)\n",
    "print(\"Sample data:\\n\", df_verified.head(10))\n",
    "print(\"\\nUnique Categories in saved file:\")\n",
    "print(df_verified['Category'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "33d7eea0-f051-4444-829d-74604de937eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate Resume count: 917\n",
      "Rows after deduplication: 22386\n"
     ]
    }
   ],
   "source": [
    "print(f\"Duplicate Resume count: {df_filtered['Resume'].duplicated().sum()}\")\n",
    "df_filtered = df_filtered.drop_duplicates(subset=['Resume'])\n",
    "print(f\"Rows after deduplication: {len(df_filtered)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2bc93a84-030a-4436-9230-b986b66c7358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories of Duplicated Resumes and Their Counts:\n",
      "Category\n",
      "Software Developer        403\n",
      "Systems Administrator     372\n",
      "Web Developer             265\n",
      "Java Developer            217\n",
      "Network Administrator     177\n",
      "Data Scientist            138\n",
      "Database Administrator     81\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Total duplicated Resume entries (all occurrences): 1653\n",
      "Total unique Resumes that were duplicated: 917\n",
      "Total rows in dataset: 23303\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "df = pd.read_csv('resumes_filtered_utf8.csv')\n",
    "\n",
    "# Step 2: Identify duplicated Resume entries (keep all occurrences)\n",
    "duplicates_mask = df['Resume'].duplicated(keep=False)\n",
    "duplicate_rows = df[duplicates_mask]\n",
    "\n",
    "# Step 3: Count Categories for duplicated Resumes\n",
    "duplicate_category_counts = duplicate_rows['Category'].value_counts()\n",
    "\n",
    "# Step 4: Print the results\n",
    "print(\"Categories of Duplicated Resumes and Their Counts:\")\n",
    "print(duplicate_category_counts)\n",
    "print(f\"\\nTotal duplicated Resume entries (all occurrences): {len(duplicate_rows)}\")\n",
    "print(f\"Total unique Resumes that were duplicated: {df['Resume'].duplicated().sum()}\")\n",
    "print(f\"Total rows in dataset: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8fe1e0e2-502d-43b0-99fa-310fb4572179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No inconsistent duplicates found (all duplicates have the same Category).\n",
      "\n",
      "Total rows after deduplication: 22386\n",
      "Unique Categories and Their Counts after deduplication:\n",
      "Category\n",
      "Software Developer        5668\n",
      "Systems Administrator     3992\n",
      "Web Developer             3422\n",
      "Database Administrator    2766\n",
      "Java Developer            2350\n",
      "Network Administrator     2188\n",
      "Data Scientist            2000\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Saved cleaned file:\n",
      "Columns: Index(['Resume', 'Category'], dtype='object')\n",
      "Total rows: 22386\n",
      "Unique Categories and Their Counts:\n",
      "Category\n",
      "Software Developer        5668\n",
      "Systems Administrator     3992\n",
      "Web Developer             3422\n",
      "Database Administrator    2766\n",
      "Java Developer            2350\n",
      "Network Administrator     2188\n",
      "Data Scientist            2000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "df = pd.read_csv('resumes_filtered_utf8.csv')\n",
    "\n",
    "# Step 2: Identify duplicated Resume entries (all occurrences)\n",
    "duplicates_mask = df['Resume'].duplicated(keep=False)\n",
    "duplicate_rows = df[duplicates_mask]\n",
    "\n",
    "# Step 3: Group duplicates by Resume and check Category consistency\n",
    "duplicate_groups = duplicate_rows.groupby('Resume')\n",
    "inconsistent_duplicates = []\n",
    "consistent_count = 0\n",
    "\n",
    "for resume, group in duplicate_groups:\n",
    "    categories = group['Category'].unique()\n",
    "    if len(categories) > 1:\n",
    "        # Inconsistent: Resume has multiple Categories\n",
    "        inconsistent_duplicates.append(group)\n",
    "    else:\n",
    "        # Consistent: Resume has the same Category for all duplicates\n",
    "        consistent_count += len(group) - 1  # Count duplicates (excluding first occurrence)\n",
    "\n",
    "# Step 4: Combine inconsistent duplicates into a DataFrame\n",
    "if inconsistent_duplicates:\n",
    "    inconsistent_df = pd.concat(inconsistent_duplicates)\n",
    "    print(\"\\nInconsistent Duplicates (Resumes with multiple Categories):\")\n",
    "    print(inconsistent_df.groupby('Resume')['Category'].apply(lambda x: ', '.join(x)).head(10))\n",
    "    print(f\"Total rows with inconsistent Categories: {len(inconsistent_df)}\")\n",
    "else:\n",
    "    print(\"\\nNo inconsistent duplicates found (all duplicates have the same Category).\")\n",
    "\n",
    "# Step 5: Remove duplicates (keep first occurrence)\n",
    "df_cleaned = df.drop_duplicates(subset=['Resume'], keep='first')\n",
    "\n",
    "# Step 6: Verify the cleaned dataset\n",
    "print(f\"\\nTotal rows after deduplication: {len(df_cleaned)}\")\n",
    "print(\"Unique Categories and Their Counts after deduplication:\")\n",
    "print(df_cleaned['Category'].value_counts())\n",
    "\n",
    "# Step 7: Save the cleaned dataset\n",
    "df_cleaned.to_csv('resumes_filtered_deduplicated_utf8.csv', index=False, encoding='utf-8')\n",
    "\n",
    "# Step 8: Save inconsistent duplicates for inspection (if any)\n",
    "if inconsistent_duplicates:\n",
    "    inconsistent_df.to_csv('inconsistent_duplicates.csv', index=False, encoding='utf-8')\n",
    "    print(\"\\nInconsistent duplicates saved to 'inconsistent_duplicates.csv'\")\n",
    "\n",
    "# Step 9: Verify the saved cleaned dataset\n",
    "df_verified = pd.read_csv('resumes_filtered_deduplicated_utf8.csv')\n",
    "print(\"\\nSaved cleaned file:\")\n",
    "print(\"Columns:\", df_verified.columns)\n",
    "print(\"Total rows:\", len(df_verified))\n",
    "print(\"Unique Categories and Their Counts:\")\n",
    "print(df_verified['Category'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1a7023-cdb5-4566-98e3-f128c2df338f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
